{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open('cornell movie-dialogs corpus/movie_lines.txt', encoding = 'utf-8', errors = 'ignore').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = open('cornell movie-dialogs corpus/movie_conversations.txt', encoding = 'utf-8', errors = 'ignore').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map each line and its id\n",
    "id_to_line = {}\n",
    "for line in lines:\n",
    "    _line = line.split(' +++$+++ ')\n",
    "    if len(_line) ==5:\n",
    "        id_to_line[_line[0]] = _line[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of all converasations\n",
    "conversation_ids = []\n",
    "for conv in conversations[:-1]: # Excluding the last row as it is empty\n",
    "    _conversation = conv.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \"\").replace(\" \",\"\")\n",
    "    # get the last elements and exclude 1st and last charactets i.e [] brackets\n",
    "    conversation_ids.append(_conversation.split(','))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting questions and answers\n",
    "questions = []\n",
    "answers = []\n",
    "for id in conversation_ids:\n",
    "    for i in range(len(id) -1):\n",
    "        questions.append(id_to_line[id[i]])\n",
    "        answers.append(id_to_line[id[i+1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning\n",
    "def text_clean(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"nobody's\", \"nobody is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"that ' s\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\' re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"won ' t\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"can not\", text)\n",
    "    text = re.sub(r\"didn't\", \"did not \", text)\n",
    "    text = re.sub(r\"don't\", \"do not\", text)\n",
    "    text = re.sub(r\"don ' t\", \"do not\", text)\n",
    "    text = re.sub(r\"haven't\", \"have not\", text)\n",
    "    text = re.sub(r\"don' t\", \"do not\", text)\n",
    "    text = re.sub(r\"isn't\", \"is not\", text)\n",
    "    text = re.sub(r\"weren't\", \"were not\", text)\n",
    "    text = re.sub(r\"who's\", \"who is\", text) \n",
    "    text = re.sub(r\"doesn't\", \"does not\", text)\n",
    "    text = re.sub(r\"aren't\", \"are not\", text)\n",
    "    text = re.sub(r\"wouldn't\", \"would not\", text)\n",
    "    text = re.sub(r\"wasn't\", \"was not\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"doin'\", \"doing\", text)\n",
    "    text = re.sub(r\"stayin'\", \"staying\", text)\n",
    "    text = re.sub(r\"takin'\", \"taking\", text)\n",
    "    text = re.sub(r\"nothin'\", \"nothing\", text)\n",
    "    text = re.sub(r\"tellin'\", \"telling\", text)\n",
    "    text = re.sub(r\"storyi\", \"story i \", text)\n",
    "    text = re.sub(r\"umnow\", \"now\", text)\n",
    "    text = re.sub(r\"now's\", \"now is \", text)\n",
    "    text = re.sub(r\"goin\", \"going\", text)\n",
    "    text = re.sub(r\"goingg\", \"going\", text)\n",
    "    text = re.sub(r\"where ya\", \"where are you\", text)\n",
    "    #text = re.sub(r\"\\in'\", \"ing\", text)\n",
    "    text = re.sub(r\"'cause'\", \"because\", text)\n",
    "    text = re.sub(r\"c'mon\", \"come on\", text)\n",
    "    text = re.sub(r\"don'tchya\", \"do not you\", text)\n",
    "    text = re.sub(r\"yeah\", \"yes\", text)\n",
    "    text = re.sub(r\"'bout\", \"about\", text)\n",
    "    text = re.sub(r\"workin'\", \"working\", text)\n",
    "    text = re.sub(r\"'me\", \"me\", text)\n",
    "    text = re.sub(r\"'til\", \"until\", text)\n",
    "    text = re.sub(r\"'em\", \"them\", text)\n",
    "    text = re.sub(r\"i ' m\", \"i am\", text)\n",
    "    text = re.sub(r\"there's\", \"there is\", text)\n",
    "    text = re.sub(r\"let's\", \"let us\", text)\n",
    "    \n",
    "    text = re.sub(r\"[-()\\\"#/@;:<>+={}.?,]\", \"\", text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the questions\n",
    "cleaned_questions = []\n",
    "for question in questions:\n",
    "    cleaned_questions.append(text_clean(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the answers\n",
    "cleaned_answers = []\n",
    "for ans in answers:\n",
    "    cleaned_answers.append(text_clean(ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary for mapping each word to its number of occurrences\n",
    "word2count = {}\n",
    "for question in cleaned_questions:\n",
    "    for word in question.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word]+= 1\n",
    "            \n",
    "for answer in cleaned_answers:\n",
    "    for word in answer.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word]+= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization and elimination of non frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 2 dictionaries to map the words of questions and answers to a unique integer\n",
    "threshold = 20\n",
    "questionswords_to_int = {}\n",
    "word_number = 0\n",
    "for word, count in word2count.items():\n",
    "    if count >= threshold:\n",
    "        questionswords_to_int[word] = word_number\n",
    "        word_number += 1\n",
    "        \n",
    "answerswords_to_int ={}\n",
    "word_number = 0\n",
    "for word, count in word2count.items():\n",
    "    if count >= threshold:\n",
    "        answerswords_to_int[word] = word_number\n",
    "        word_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding tokens to the dictionaries\n",
    "tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n",
    "for token in tokens:\n",
    "    questionswords_to_int[token] = len(questionswords_to_int) +1\n",
    "    \n",
    "for token in tokens:\n",
    "    answerswords_to_int[token] = len(answerswords_to_int) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the inverse dictionary of the answerswords_to_int dictionalry for inverse mapping\n",
    "answersint_to_words = {w_i: w for w , w_i in answerswords_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add EOS at the end of every answer\n",
    "for i in range(len(cleaned_answers)):\n",
    "    cleaned_answers[i] += ' <EOS>'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translating all the questions and the answers into integers (frequence of occurence of a word)\n",
    "# Replacing all the words that were filtered out by <OUT>\n",
    "\n",
    "questions_to_int =[]\n",
    "for questions in cleaned_questions:\n",
    "    integers =[]\n",
    "    for word in questions.split():\n",
    "        if word not in questionswords_to_int:\n",
    "            integers.append(questionswords_to_int['<OUT>'])\n",
    "        else:\n",
    "            integers.append(questionswords_to_int[word])\n",
    "    questions_to_int.append(integers)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_to_int =[]\n",
    "for answers in cleaned_answers:\n",
    "    integers =[]\n",
    "    for word in answers.split():\n",
    "        if word not in answerswords_to_int:\n",
    "            integers.append(answerswords_to_int['<OUT>'])\n",
    "        else:\n",
    "            integers.append(answerswords_to_int[word])\n",
    "    answers_to_int.append(integers)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the questions and answers by the length of the question\n",
    "sorted_clean_questions =[]\n",
    "sorted_clean_answers = []\n",
    "for length in range(1,25+1):\n",
    "    for i in enumerate(questions_to_int):\n",
    "        if len(i[1]) == length:\n",
    "            sorted_clean_questions.append(questions_to_int[i[0]])\n",
    "            sorted_clean_answers.append(answers_to_int[i[0]])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
